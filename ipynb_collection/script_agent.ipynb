{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0108381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: sentence-transformers in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: openai in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (0.2.6)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: packaging in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from requests->youtube-transcript-api) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from requests->youtube-transcript-api) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: colorama in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\ai_prompt\\second\\ai_agent\\ai_agent_work2\\youtube_agent\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-transcript-api langchain sentence-transformers faiss-cpu openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adba4d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351febde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3294ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def get_youtube_transcript(video_url: str) -> str:\n",
    "    \"\"\"\n",
    "    유튜브 URL에서 비디오 ID를 추출하고 스크립트를 가져옵니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_url = urlparse(video_url)\n",
    "        if parsed_url.hostname in [\"youtu.be\"]:\n",
    "            video_id = parsed_url.path[1:]\n",
    "        else:\n",
    "            qs = parse_qs(parsed_url.query)\n",
    "            video_id = qs.get(\"v\", [None])[0]\n",
    "        if not video_id:\n",
    "            raise ValueError(\"유효한 유튜브 URL이 아닙니다.\")\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])\n",
    "        transcript = \" \".join([item['text'] for item in transcript_list])\n",
    "        print(\"✅ 유튜브 스크립트를 성공적으로 가져왔습니다.\")\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 스크립트를 가져오는 중 오류가 발생했습니다: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8791043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_search_vectordb(text: str, query: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    주어진 텍스트로 FAISS 벡터 DB를 생성하고 쿼리와 가장 유사한 청크를 검색합니다.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    # 2. 텍스트 분할 (Chunking)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_text(text)\n",
    "    print(f\"✅ 텍스트를 {len(docs)}개의 조각으로 나누었습니다.\")\n",
    "\n",
    "    # 3. 임베딩 모델 로드 및 텍스트 벡터화\n",
    "    print(\"⏳ 임베딩 모델을 로드하고 텍스트를 벡터로 변환합니다...\")\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    embeddings = model.encode(docs, convert_to_tensor=False)\n",
    "    \n",
    "    # FAISS는 float32 타입을 요구합니다.\n",
    "    embeddings = np.array(embeddings).astype('float32')\n",
    "    print(\"✅ 텍스트 벡터화 완료.\")\n",
    "\n",
    "    # 4. FAISS 벡터 DB 생성 및 저장\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    print(f\"✅ FAISS 벡터 DB 생성 완료. (벡터 차원: {dimension})\")\n",
    "\n",
    "    # 5. 쿼리 벡터화 및 유사도 검색\n",
    "    query_vector = model.encode([query], convert_to_tensor=False).astype('float32')\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    \n",
    "    # 가장 관련성 높은 텍스트 청크들을 반환\n",
    "    relevant_docs = [docs[i] for i in indices[0] if 0 <= i < len(docs)]\n",
    "    print(f\"✅ 관련성 높은 {k}개의 문서를 찾았습니다.\")\n",
    "    return relevant_docs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c555cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_gpt(context_docs: list, query: str) -> str:\n",
    "    \"\"\"\n",
    "    검색된 문맥을 바탕으로 OpenAI GPT 모델을 사용하여 요약을 생성합니다.\n",
    "    \"\"\"\n",
    "    if not context_docs:\n",
    "        return \"요약할 내용을 찾지 못했습니다.\"\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_docs)\n",
    "    \n",
    "    # GPT 모델에 전달할 메시지(프롬프트) 구성\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"당신은 유튜브 스크립트의 핵심 내용을 요약하는 유용한 AI 어시스턴트입니다. 주어진 내용을 바탕으로 사용자의 질문에 대해 간결하고 명확하게 한국어로 답변해주세요.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            아래는 유튜브 동영상 스크립트에서 추출한 핵심 내용입니다.\n",
    "            이 내용을 바탕으로 내 질문에 대해 자연스러운 한국어로 요약해 주세요.\n",
    "\n",
    "            [핵심 내용]\n",
    "            {context_text}\n",
    "\n",
    "            [내 질문]\n",
    "            {query}\n",
    "\n",
    "            [요약 답변]\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"⏳ OpenAI GPT 모델을 통해 요약을 생성합니다...\")\n",
    "    try:\n",
    "        # OpenAI API 호출\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # 또는 \"gpt-3.5-turbo\" 등 다른 모델 사용 가능\n",
    "            messages=messages,\n",
    "            temperature=0.7, # 창의성 조절 (0~2)\n",
    "        )\n",
    "        print(\"✅ AI 요약 생성 완료!\")\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"❌ AI 요약 생성 중 오류 발생: {e}\")\n",
    "        return \"AI 요약 생성에 실패했습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfe34db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 유튜브 스크립트를 성공적으로 가져왔습니다.\n",
      "✅ 텍스트를 6개의 조각으로 나누었습니다.\n",
      "⏳ 임베딩 모델을 로드하고 텍스트를 벡터로 변환합니다...\n",
      "✅ 텍스트 벡터화 완료.\n",
      "✅ FAISS 벡터 DB 생성 완료. (벡터 차원: 384)\n",
      "✅ 관련성 높은 5개의 문서를 찾았습니다.\n",
      "⏳ OpenAI GPT 모델을 통해 요약을 생성합니다...\n",
      "✅ AI 요약 생성 완료!\n",
      "\n",
      "\n",
      "--- 최종 요약 결과 (GPT) ---\n",
      "이 동영상은 \"아침밥 차려주는 남편\"이라는 유튜브 채널을 운영하는 주인공의 이야기입니다. 주인공은 가족을 위해 매일 아침밥을 준비하며, 그 과정을 영상으로 기록하여 채널에 올립니다. 그는 자신의 요리나 베이킹을 혼자 먹지 않고, 주변 사람들과 나누고 그들의 반응을 영상에 담습니다. 주인공은 요리를 통해 요리 실력을 키워가고 있으며, 유튜브 시작의 계기와 채널명이 된 배경도 설명합니다. 또한 운동을 통해 건강을 관리하며, 얼굴 공개 계획은 없고, 평범한 목소리 대신 독특한 목소리로 콘텐츠를 꾸미고 있습니다. 요리의 맛 평가에 솔직하며, 주로 즉흥적으로 요리하는 방식을 고수하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. 요약하고 싶은 유튜브 동영상 URL을 입력하세요.\n",
    "    YOUTUBE_URL = \"https://youtu.be/6RomdaxSUtY?si=DdlSQ-DLfD0y3Wx2\"\n",
    "    # 2. 스크립트를 가져옵니다.\n",
    "    transcript_text = get_youtube_transcript(YOUTUBE_URL)\n",
    "\n",
    "    if transcript_text:\n",
    "        # 3. 요약의 기준이 될 질문을 정의합니다.\n",
    "        summary_query = \"이 동영상의 핵심 내용은 무엇인가요? 주요 개념들을 설명해주세요.\"\n",
    "        \n",
    "        # 4. 벡터 DB에서 관련 내용을 검색합니다.\n",
    "        relevant_documents = create_and_search_vectordb(transcript_text, summary_query)\n",
    "        \n",
    "        # 5. 검색된 내용을 바탕으로 GPT AI 요약을 생성합니다.\n",
    "        final_summary = summarize_with_gpt(relevant_documents, summary_query)\n",
    "        \n",
    "        print(\"\\n\\n--- 최종 요약 결과 (GPT) ---\")\n",
    "        print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e9fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
